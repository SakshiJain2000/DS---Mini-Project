# -*- coding: utf-8 -*-
"""DS- Minor Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/SakshiJain2000/46e733cf3337e61048613fddb4cea3d1/ds-minor-project.ipynb
"""

#PreProcess data
#Scaling down the image to specific value

from skimage.io import imread
from skimage.transform import resize
import os
import os.path
 
filepath = r'/content/DS- Minor Project'
if filepath:
  fp = Image.open('/content/DS- Minor Project/bike/bike_image.jpg', mode='r')
  exclusive_fp = True

img = fp.resize((200,400))
img.save('img.jpg')

print(fp.size)
print(img.size)

import PIL
from PIL import Image
import numpy as np
 
# coverting image to array

arr_image = PIL.Image.open('/content/DS- Minor Project/bike/bike_image.jpg')
image_sequence = arr_image.getdata()
image_array = np.array(image_sequence)
print(image_array)

#Converting 2-D array to 1-D array - Flattening of an image

result = image_array.flatten()
print("New resulting array: ", result)

#Creating dataframe by iterating through the Images

from scipy import ndimage
import numpy as np
import os
import cv2

def main():
    path = "/content/DS- Minor Project/bike/bike_image.jpg"
    outpath = "/content/DS- Minor Project/rotated image"

    for image_path in os.listdir(path):
      input_path = os.path.join(path, image_path)
      image_to_rotate = ndimage.imread(input_path)

      rotated = ndimage.rotate(image_to_rotate, 45)
      fullpath = os.path.join(outPath, 'rotated_'+image_path)
      misc.imsave(fullpath, rotated_)

if __name__ == "__main__":
   print(main)

#Creating dataframe for iteration

import numpy as np
import pandas as pd

if __name__ == '__main__':
   data = {'column a': pd.Series(np.random.randint(0,100,3)),
           'column b': pd.Series(np.random.randint(0,100,3)),
           'column c': pd.Series(np.random.randint(0,100,3))}

   df = pd.DataFrame(data)
   df.index = ['row 1', 'row 2', 'row 3']
   print(df)

# Commented out IPython magic to ensure Python compatibility.
#Apply any classification algorithm with best parameters using Gridserach CV

import imutils
import cv2
import os
import numpy as np
!pip install histograms
from histograms import histograms
import histograms as hist

def extract_color_histogram(image,bins=(8,8,8)):

#extract a 3D color histogramfrom the HSV color space using the supplies numbr of 'bins' per channel.
 hsv = cv2.cvtcolor(image,cv2.COLOR_BGR2HSV)
 hist = cv2.calcHist([hsv], [0,1,2], None, bins, [0,180,0,256,0,256])

#handle normalizing the histogram if we are using OpenCV 2.4.X
if imutils.is_cv2():
     hist = cv2.normalize(hist)

#otherwise, perform "in place" normalization in OpenCV 3

else: 
#     %s(cv2.normalize(hist,hist))

#return the flattened histogram as the feature vector

return hist.flatten()

import numpy as np
from skimage.io import imread
from skimage.transform import resize
import os
import os.path
!pip install scikit-learn
import sklearn
import sklearn.neighbors
from sklearn.model_selection import train_test_split

print("Describing images...")
imagepath = '/content/DS- Minor Project/bike/bike_image.jpg'

rawimages = []
features = []
labels = []

for (i,imagepath) in enumerate(imagepath):

  image = cv2.imread(imagepath)
  label = imagepath.split(os.path.sep)[-1].split(".")[0]

def image_to_feature_vector(image,size=(32,32)):
  return cv2.resize(image,size).flatten()

  pixels = image_to_feature_vector(image)
  hist = extract_color_histogram(image)

  rawimages.append(pixels)
  feautures.append(hist)
  labels.append(label)

  if i > 0 and i %1000 == 0:
    print(" processing {}/{}".format (i, len(imagepath)))

rawimages = np.array(rawimages)
features = np.array(features)
labels = np.array(labels)
print("pixels matrix: {:.2f} MB".format(
     rawimages.nbytes / (1024 * 1000.0)))

print("features matrix: {:.2f} MB".format(
     features.nbytes / (1024 * 1000.0)))

#confusion matrix in sklearn

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

#actual values

actual = [1,0,0,1,0,0,1,0,0,1]

#predicted values
predicted = [1,0,0,1,0,0,0,1,0,0]

#confusin matrix
matrix = confusion_matrix(actual, predicted, labels=[1,0])
print('confusion matrix : \n', matrix)

#outcome values order in sklearn
tp, fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)
print('outcome values : \n', tp, fn, fp, tn)

#classification report for precision, recall f1-score and accuracy
matrix = classification_report(actual,predicted,labels=[1,0])
print('classification report ;\n', matrix)